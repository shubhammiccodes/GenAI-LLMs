{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fa0697-4b3d-4237-afb2-22f38025ce56",
   "metadata": {},
   "source": [
    "# Data Sampling using Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bd8cb-f074-4880-9f26-16ffae364d70",
   "metadata": {},
   "source": [
    "## import required pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b6ceb2-6c64-408e-8777-43348a61ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34b9d1-acf6-4bd7-9699-71d8b457d7b2",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "146915e3-d8f6-4292-b244-800f18c76abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", \"r\") as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "913f92b4-ccef-4fa1-bd1f-1a3b6f43bd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice was beginning to get very tired of sitting by her sister\\non the bank, and of having nothing to'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "624f25c6-f341-41f2-ab28-be6c44246511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of context window\n",
    "CONTEXT_LENGTH = 10\n",
    "\n",
    "# how many token to jump or skip to find next iteration\n",
    "STRIDE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a922bfd-76ae-40c7-8e69-9b5bb3aaf3ee",
   "metadata": {},
   "source": [
    "## create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca3d061-97bd-4f98-92f5-6a71e4e174f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5a538bb-bd0a-49a4-a36f-8952273b8fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42421"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the raw_text\n",
    "tokens = tokenizer.encode(raw_text)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e112f94f-83fc-4c57-b168-2e237bcbe126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample of 10 words\n",
    "sample = tokens[:CONTEXT_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a156979-4575-4979-a6bc-c23b91a8d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = Alice was beginning to\n",
      "target =  get\n"
     ]
    }
   ],
   "source": [
    "# logic to create Sliding window\n",
    "print(f\"input = {tokenizer.decode(sample[:4])}\")\n",
    "print(f\"target = {tokenizer.decode(sample[4:4+1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd25921-45d8-4ff6-bfca-b2fc3f25fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44484] => [373]\n",
      "[44484, 373] => [3726]\n",
      "[44484, 373, 3726] => [284]\n",
      "[44484, 373, 3726, 284] => [651]\n",
      "[44484, 373, 3726, 284, 651] => [845]\n",
      "[44484, 373, 3726, 284, 651, 845] => [10032]\n",
      "[44484, 373, 3726, 284, 651, 845, 10032] => [286]\n",
      "[44484, 373, 3726, 284, 651, 845, 10032, 286] => [5586]\n",
      "[44484, 373, 3726, 284, 651, 845, 10032, 286, 5586] => [416]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(sample), STRIDE):\n",
    "    print(f\"{sample[:i]} => {sample[i:i+1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b12df695-1fde-4327-ac70-a749b9f7b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice =>  was\n",
      "Alice was =>  beginning\n",
      "Alice was beginning =>  to\n",
      "Alice was beginning to =>  get\n",
      "Alice was beginning to get =>  very\n",
      "Alice was beginning to get very =>  tired\n",
      "Alice was beginning to get very tired =>  of\n",
      "Alice was beginning to get very tired of =>  sitting\n",
      "Alice was beginning to get very tired of sitting =>  by\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(sample), STRIDE):\n",
    "    print(f\"{tokenizer.decode(sample[:i])} => {tokenizer.decode(sample[i:i+1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b378c-5163-417f-be17-e84d69cb1066",
   "metadata": {},
   "source": [
    "# get entire data into sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c81ca70a-e4f0-4b86-8616-f709e0640da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all input chunks\n",
    "input_ids = []\n",
    "\n",
    "# store all target chunks\n",
    "target_ids = []\n",
    "\n",
    "for i in range(1, len(tokens) - CONTEXT_LENGTH, STRIDE):\n",
    "    input_chunk = tokens[i : i + CONTEXT_LENGTH]\n",
    "    target_chunk = tokens[i+1 : i + CONTEXT_LENGTH + 1]\n",
    "\n",
    "    # stire all input and taerget chunks\n",
    "    input_ids.append(torch.tensor(input_chunk))\n",
    "    target_ids.append(torch.tensor(target_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65d98107-cd31-44f4-bae0-8e08b0e58f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42410, 42410)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids), len(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d35278d7-2953-445e-8d58-c96294f7100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  373,  3726,   284,   651,   845, 10032,   286,  5586,   416,   607]),\n",
       " tensor([ 3726,   284,   651,   845, 10032,   286,  5586,   416,   607,  6621]),\n",
       " tensor([  284,   651,   845, 10032,   286,  5586,   416,   607,  6621,   198]),\n",
       " tensor([  651,   845, 10032,   286,  5586,   416,   607,  6621,   198,   261]),\n",
       " tensor([  845, 10032,   286,  5586,   416,   607,  6621,   198,   261,   262]),\n",
       " tensor([10032,   286,  5586,   416,   607,  6621,   198,   261,   262,  3331]),\n",
       " tensor([ 286, 5586,  416,  607, 6621,  198,  261,  262, 3331,   11]),\n",
       " tensor([5586,  416,  607, 6621,  198,  261,  262, 3331,   11,  290]),\n",
       " tensor([ 416,  607, 6621,  198,  261,  262, 3331,   11,  290,  286]),\n",
       " tensor([ 607, 6621,  198,  261,  262, 3331,   11,  290,  286, 1719])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e07313ac-e109-4f85-828c-b97414e76e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3726,   284,   651,   845, 10032,   286,  5586,   416,   607,  6621]),\n",
       " tensor([  284,   651,   845, 10032,   286,  5586,   416,   607,  6621,   198]),\n",
       " tensor([  651,   845, 10032,   286,  5586,   416,   607,  6621,   198,   261]),\n",
       " tensor([  845, 10032,   286,  5586,   416,   607,  6621,   198,   261,   262]),\n",
       " tensor([10032,   286,  5586,   416,   607,  6621,   198,   261,   262,  3331]),\n",
       " tensor([ 286, 5586,  416,  607, 6621,  198,  261,  262, 3331,   11]),\n",
       " tensor([5586,  416,  607, 6621,  198,  261,  262, 3331,   11,  290]),\n",
       " tensor([ 416,  607, 6621,  198,  261,  262, 3331,   11,  290,  286]),\n",
       " tensor([ 607, 6621,  198,  261,  262, 3331,   11,  290,  286, 1719]),\n",
       " tensor([6621,  198,  261,  262, 3331,   11,  290,  286, 1719, 2147])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c492905-b0f9-4873-9c9b-9d7e8f134cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmenv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
